# The ethics of good design: A principle for the connected age

_Captured: 2016-12-04 at 18:43 from [medium.com](https://medium.com/swlh/dieter-rams-ten-principles-for-good-design-the-1st-amendment-4e73111a18e4?source=userActivityShare-c79006fee040-1480873406)_

![](https://cdn-images-1.medium.com/max/1000/1*OTLgUdYujMp2YDUiq-oh8g.png)

There's a book on my shelf titled _Less and More: The Design Ethos of Dieter Rams. _It's a massive, 800 page compendium of Rams' life's work and values, as well as essays by prominent designers around the world on his impact on the pursuit of good design. An excerpt from one of those essays on page 703…

> "Dieter Rams stands for integrity in design," says design critic Hugh Pearlman, "He stands for true functionalism. He is anti-styling, anti-waste. He is against the throwaway society."

Rams noticed far too much wasteful, irritating, confusing and thoughtless design around him. By the late 1970s he'd had enough. He responded with what may be the most perennial mark of his legacy, his widely celebrated **[Ten Principles for Good Design**](https://www.vitsoe.com/us/about/good-design)**:**

> 1\. Good design is innovative.

> 2\. Good design makes a product useful.

> 3\. Good design is aesthetic.

> 4\. Good design makes a product understandable.

> 5\. Good design is unobtrusive.

> 6\. Good design is honest.

> 7\. Good design is long-lasting.

> 8\. Good design is thorough down to the last detail.

> 9\. Good design is environmentally friendly.

> 10\. Good design is as little design as possible.

I've added an 11th principle to my personal version of Rams' doctrine. It's a modification that helps me make decisions as both a product designer and as a user in a digital, connected era. Before getting into what that is, it's important to have a look at the world of product design today from a higher vantage point, and see how that world has exposed a gap in the original ten principles -- a gap worth addressing.

![](https://cdn-images-1.medium.com/max/1000/1*AiyLWKZgJuVaaZabkyF-6Q.png)

> "There is no longer room for irrelevant things. We have no longer got the resources. Irrelevance is out." -- Dieter Rams

![](https://cdn-images-1.medium.com/max/1000/1*BD-ddbxHBEj_pmQFMwiANg.jpeg)

> _Modulares Hi-Fi-Audiosystem (1959). Photo: Braden Kowitz_

The enduring nature of Rams' values shows us how fundamental they've been for good product design. Even as we enter the connected age they are unremitting. His ideals recognize what most of us consider to be the more evident qualities of a good design: Innovation, simplicity, form from function. However, he also called on us to design responsibly, to imbue qualities like efficiency, honesty, and durability into the products we create.

But a loophole has since emerged. A loophole exploited on such a massive scale that it's hard to even see it.

Now that a new class of products have integrated themselves into our daily lives, along came design characteristics Rams couldn't have forecasted 40 years ago. Today's digital products can meet a Ramsian definition of "good design" while at the same time getting away with transgressions that we need to admit exist.

Though Rams was reacting to what he saw as a jumbled, confusing world full of poor design, one thing could generally be counted on: The user was empowered to decide what products to allow into their lives. They decided which products they truly loved. They decided when and to what extent they would use them. They were in control.

Today, that kind of control is shifting away from a product's user and toward its designer by capitalizing on cognitive vulnerabilities we all have as human beings. It's both perplexing and impressive to me how creators of such products have evaded scrutiny, let alone responsibility. For example, studies showing how many times we check our devices each day (75 to 150 depending on the study) are often followed by narratives using the language and tone of self-blame (addiction, narcissism, boredom, etc). Those narratives are rarely accompanied by what's happening on the other side of the product development cycle: The designer's invisible hand meddling with the controls.

How is that happening? I see a cocktail of three main ingredients.

#### 1\. Powerful tactics rooted in behavioral research.

We're getting good at exploiting known cognitive weaknesses and quirks. Really good. It's hard not to encounter references to B.F. Skinner's **[operant conditioning chamber**](https://en.wikipedia.org/wiki/Operant_conditioning_chamber), or "Skinner box", when digging into the principles of behavior design. It's the foundation of **[variable rewards**](https://en.wikipedia.org/wiki/Reinforcement#Intermittent_reinforcement.3B_schedules), and we're all suckers for them. For a blueprint on how to bake addictive properties like that into products, there's _Hooked: How to Build Habit-Forming Products _authored by Silicon Valley consultant Nir Eyal. He appropriately calls it the "Hook model."

Silicon Valley entrepreneurs, many armed with tactics learned from B.J. Fogg and his Persuasive Technology Lab at Stanford University, have laced a generation of products with an array of characteristics proven to persuade and form habits. Tristan Harris, once an apprentice of Fogg's, **[exposes in detail**](https://medium.com/swlh/how-technology-hijacks-peoples-minds-from-a-magician-and-google-s-design-ethicist-56d62ef5edf3#.omfybhlgs) some of the potencies of the products on your device right now. I think of Harris as a sort of Ed Snowden of Silicon Valley in how he's boldly thrown shade on practices he's known up close. He gives **[several examples**](https://medium.com/swlh/how-technology-hijacks-peoples-minds-from-a-magician-and-google-s-design-ethicist-56d62ef5edf3#.ukf57fzal) of social approval and reciprocity, bundling user needs with business desires, choice control, bottomless bowls, algorithmically orchestrated nudges, and other brain hacks. These aren't dark patterns. These are more fundamental. More biologic.

#### 2\. Incentives for success that discount or exclude user wellbeing.

A well-designed home coffee maker provides an easy-to-understand, pleasurable brewing experience that produces the kind of coffee that makes you think it's from a local hand-crafted coffee shop. And it would do that on your schedule. How well it does this is the measure of its success. An inhumane, manipulative coffee maker would know how long it's been since you consumed your last cup. It would know the caffeine levels in your blood, store your consumption patterns, automatically brew you another cup of coffee, nudging you to consume it when your usage graphs determine when you're most likely to succumb. And every time you did, its creator would get paid by the coffee producer. How much coffee it can get you to consume is what defines success. Your risk of chronic over-caffeination is not its concern.

It's often said that if you're not paying for a product then you are what is being sold. This is as true as it ever was. But now we've figured out how to keep that true while still getting users to pay. They pay in the new currency of time and attention. The attention someone once gave to personal interactions, objects on the street they're walking on, or their kid's piano recital is instead siphoned off by the product. Success is too often determined by how high an attention tax they can impose on us.

#### 3\. The compounding effect of rapid optimization and deployment.

Picture a Las Vegas casino filled with conventional slot machines. The machines are already designed to produce variable rewards, near-wins, and enchant people into a trance. Now imagine they're continuously measured, A/B tested and optimized with algorithmic precision, with ever more effective versions being rolled out without losing a minute of uptime. That's what today's rapid product deployment cycle is able to do when fed attention-driven success incentives and methods of persuasion as inputs.

Carefully crafted experiments determine which behavioral persuasion variation is more effective. Combine this with the speed at which we can analyze those experiments and deploy tweaks. The result is products that get stickier and stickier. The sophistication of the technology for how growth is achieved is too easily and often developed around quickly tuning a product's narcotic properties, not necessarily its capacity for improving wellbeing.

### A design principle for the connected age

With that story of how the design environment is changing, let's come back to the idea of updating the principles.

#### Reframing the principles

Rams' principles are often called the _Ten Commandments of Good Design_. But that makes me think of absolute laws. Stone tablets. The problem with that analogy is that they take on a quality of rigidity and completeness in people's minds that is by nature not future-proof. It's for that reason that I think of these principles more like a charter, or a constitution. This makes them more open to interpretation. But more importantly, it makes them amendable. Oversights can be addressed. Holes can be plugged. Inequities can be made right. You get the idea. As our environment changes, so then can the principles guiding us to through it.

Thomas Jefferson kept a version of the New Testament that he edited himself. Historians **[say**](https://en.wikipedia.org/wiki/Jefferson_Bible#cite_note-24) he "did not produce his small book to shock or offend a somnolent world; he composed it for himself, for his devotion, for his assurance, for a more restful sleep at nights and a more confident greeting of the mornings." That's how I think of modifying Dieter Rams' principles. The original is sacrosanct, so I forked my own version.

Here's the amendment:

> **11\. Good design is ethical. **The product places the user's interest at the center of its purpose. Any effort to influence the user's agency or behavior is in the spirit of their own positive wellbeing, and the wellbeing of those around them.

Rams' **[6th principle**](https://www.vitsoe.com/us/about/good-design) comes closest to addressing this. But here he is talking about a product's integrity in terms of making false promises, or overstating its value. It speaks to the kind of manipulation that misleads, not to the darker kind that avoids lying to you while exploiting your weaknesses. The first is _once shame on me, twice shame on you_. The second knows no limits. Products violating the 6th principle you won't use again. Products violating the 11th principle can ensnare you at the cost of your own interests.

#### How do we define design ethics?

At this point I know what you're thinking: _Ok, but who gets to decide what is ethical?_ I can't lie. I really don't know. But neither do I know who gets to decide, for example, what is aesthetic. I'm forming my own threshold for what is ethical, what isn't, what falls in the shades between, and how to factor that into my work and what products I allow into my life. And I hope you do, too. The important point is for design ethics to have a seat at the table along with every other product interest and influencing force. Not just a pat on the head.

With all this in mind, figuring out what questions to ask always helps me think through complicated things. Some that I've been asking are…

  * What might success metrics include other than growing the wedge of attention in the user's pie of limited time?
  * Are there qualities of a product's purpose that make it justifiable to deploy behavioral design tactics? Should a product with a mission to teach kids math have more license than, say, a dating app? Why?
  * How do we know when users have crossed over from sole agency to doing something they wouldn't have otherwise done? Can we measure that?
  * Should there be some form of regulation or other structures that discourage malpractice? How would those be enforced?
  * Who on the product side should be accountable for ethical design? How do we control for conflicts of interest?

It gives me confidence that this conversation has already begun. Though only one of Fogg's courses confronts the ethics of persuasion, and less than 1% of Eyal's book discusses the morality of manipulation, they should be commended. But it's Harris, by **[offering a clear picture of what is, and a vision for what could be**](http://www.ted.com/talks/tristan_harris_how_better_tech_could_protect_us_from_distraction), who has illuminated this issue as a distinct concern. He's inspired me to the level of keeping my own personal copy of Rams' design precepts. Where the story goes, though, isn't clear to me. But pausing to ask two fundamental questions of ourselves can help us take the next steps: _As a user, did what I just do feel 100% like my choice? As a designer, is what I'm about to release to the world good for the user's wellbeing?_

> "Question everything generally thought to be obvious." -- Dieter Rams

If you liked this perspective and want to advance the conversation, please consider recommending and sharing.

![](https://cdn-images-1.medium.com/max/800/1*yPahSR4b3RPaZibwYqiPcw.png)

> _Thank you_

#### For further reading…

A list of resources and referenced work.
